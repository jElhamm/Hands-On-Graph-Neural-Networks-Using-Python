{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands On Graph Neural Networks Using Python  -  CHAPTER 10**"
      ],
      "metadata": {
        "id": "bS3QIfDzIzkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- This script sets up and runs experiments with two graph neural network models, VGAE and DGCNN, using the Cora dataset from PyTorch Geometric.\n",
        "\n",
        "- It first defines several classes: `Encoder` for the VGAE encoder network, `VGAEModel` for the VGAE model including training and testing methods, `SealProcessing` for processing graph data with special transformations, and `DGCNNModel` for a deep graph convolutional neural network with 1D convolutional layers.\n",
        "\n",
        "- The `GraphModeling` class orchestrates data loading, model training, and evaluation for both models. It initializes the dataset, processes it, and trains the VGAE model to predict graph link probabilities, evaluating performance with metrics like AUC and average precision.\n",
        "\n",
        "- It also trains the DGCNN model for edge classification, with separate loaders for positive and negative edges. Finally, it prints out the results from both models' evaluations."
      ],
      "metadata": {
        "id": "cJ2ReqirILyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV5GrU4N4gEN",
        "outputId": "8182a7d7-00f7-43ba-e5d8-61d886039d34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.2/986.2 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.nn import GCNConv, VGAE, global_sort_pool\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix\n",
        "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout, BCEWithLogitsLoss\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "jBiSlgUd_u04"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Set random seed**\n"
      ],
      "metadata": {
        "id": "LFex3Kixnqpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "metadata": {
        "id": "bHeEVYpW_zyf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encoder Class**\n",
        "\n",
        "- This class implements the encoder part of the Variational Graph Autoencoder (VGAE) model. It uses two GCNConv layers to compute the mean and log standard deviation for node embeddings, which are crucial for learning latent representations in the VGAE framework."
      ],
      "metadata": {
        "id": "07Io4ov3KYzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dim_in, 2 * dim_out)\n",
        "        self.conv_mu = GCNConv(2 * dim_out, dim_out)\n",
        "        self.conv_logstd = GCNConv(2 * dim_out, dim_out)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
      ],
      "metadata": {
        "id": "WwdsVX0r_2P-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VGAE model Class**\n",
        "\n",
        "- This class manages the VGAE model, including its initialization, training, and evaluation. It initializes the VGAE model with an Encoder, defines an Adam optimizer for training, and provides methods to train the model on training data and test its performance on validation or test data.\n"
      ],
      "metadata": {
        "id": "6gud8uM9K6l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGAEModel:\n",
        "    def __init__(self, dataset, device):\n",
        "        self.device = device\n",
        "        self.model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
        "\n",
        "    def train(self, train_data):\n",
        "        self.model.train()\n",
        "        self.optimizer.zero_grad()\n",
        "        z = self.model.encode(train_data.x, train_data.edge_index)\n",
        "        loss = self.model.recon_loss(z, train_data.pos_edge_label_index) + \\\n",
        "               (1 / train_data.num_nodes) * self.model.kl_loss()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return float(loss)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data):\n",
        "        self.model.eval()\n",
        "        z = self.model.encode(data.x, data.edge_index)\n",
        "        return self.model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)"
      ],
      "metadata": {
        "id": "hl2w5Ccq_5BF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SealProcessing Class**\n",
        "\n",
        "- This class contains a static method for processing graph data. It performs operations such as creating subgraphs, computing shortest paths, and generating node labels based on these paths. The processed data is then used to create Data objects suitable for input into a graph neural network."
      ],
      "metadata": {
        "id": "tygH4T_HJ-Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SealProcessing:\n",
        "    @staticmethod\n",
        "    def process(dataset, edge_label_index, y):\n",
        "        data_list = []\n",
        "\n",
        "        for src, dst in edge_label_index.t().tolist():\n",
        "            sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph([src, dst], 2, dataset.edge_index, relabel_nodes=True)\n",
        "            src, dst = mapping.tolist()\n",
        "            mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
        "            mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
        "            sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
        "            src, dst = (dst, src) if src > dst else (src, dst)\n",
        "            adj = to_scipy_sparse_matrix(sub_edge_index, num_nodes=sub_nodes.size(0)).tocsr()\n",
        "\n",
        "            idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "            adj_wo_src = adj[idx, :][:, idx]\n",
        "            idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "            adj_wo_dst = adj[idx, :][:, idx]\n",
        "\n",
        "            d_src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
        "            d_src = np.insert(d_src, dst, 0, axis=0)\n",
        "            d_src = torch.from_numpy(d_src)\n",
        "            d_dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
        "            d_dst = np.insert(d_dst, src, 0, axis=0)\n",
        "            d_dst = torch.from_numpy(d_dst)\n",
        "\n",
        "            dist = d_src + d_dst\n",
        "            z = 1 + torch.min(d_src, d_dst) + dist // 2 * (dist // 2 + dist % 2 - 1)\n",
        "            z[src], z[dst], z[torch.isnan(z)] = 1., 1., 0.\n",
        "            z = z.to(torch.long)\n",
        "            node_labels = F.one_hot(z, num_classes=200).to(torch.float)\n",
        "            node_emb = dataset.x[sub_nodes]\n",
        "            node_x = torch.cat([node_emb, node_labels], dim=1)\n",
        "            data = Data(x=node_x, z=z, edge_index=sub_edge_index, y=y)\n",
        "            data_list.append(data)\n",
        "\n",
        "        return data_list"
      ],
      "metadata": {
        "id": "gSIqV25IKFcl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deep Graph Convolutional Neural Network (DGCNN) Class**\n",
        "\n",
        "- This class implements the Deep Graph Convolutional Neural Network (DGCNN). It consists of several GCNConv layers for feature extraction, followed by 1D convolutional layers for further processing. It also includes dropout and linear layers for classification. The model processes graph data to produce edge classification outputs."
      ],
      "metadata": {
        "id": "JOEaJyVqzCAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DGCNNModel(torch.nn.Module):\n",
        "    def __init__(self, dim_in, k=30):\n",
        "        super().__init__()\n",
        "        self.gcn1 = GCNConv(dim_in, 32)\n",
        "        self.gcn2 = GCNConv(32, 32)\n",
        "        self.gcn3 = GCNConv(32, 32)\n",
        "        self.gcn4 = GCNConv(32, 1)\n",
        "        self.k = k\n",
        "        self.conv1 = Conv1d(1, 16, 97, 97)\n",
        "        self.conv2 = Conv1d(16, 32, 5, 1)\n",
        "        self.maxpool = MaxPool1d(2, 2)\n",
        "        self.linear1 = Linear(352, 128)\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.linear2 = Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        h1 = self.gcn1(x, edge_index).tanh()\n",
        "        h2 = self.gcn2(h1, edge_index).tanh()\n",
        "        h3 = self.gcn3(h2, edge_index).tanh()\n",
        "        h4 = self.gcn4(h3, edge_index).tanh()\n",
        "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
        "        h = global_sort_pool(h, batch, k=self.k)\n",
        "        h = h.view(h.size(0), 1, h.size(-1))\n",
        "        h = self.conv1(h).relu()\n",
        "        h = self.maxpool(h)\n",
        "        h = self.conv2(h).relu()\n",
        "        h = h.view(h.size(0), -1)\n",
        "        h = self.linear1(h).relu()\n",
        "        h = self.dropout(h)\n",
        "        h = self.linear2(h).sigmoid()\n",
        "        return h"
      ],
      "metadata": {
        "id": "8Jdr5zBhx7jf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GraphModeling Class**\n",
        "\n",
        "- This class is the main driver for the experiments. It initializes the dataset and splits it into training, validation, and test sets. It includes methods to run both the VGAE and DGCNN models. For VGAE, it handles training and evaluation, while for DGCNN, it processes data, trains the model, and evaluates performance using AUC and average precision metrics."
      ],
      "metadata": {
        "id": "VaQocCUYzMHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphModeling:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.dataset = Planetoid('.', name='Cora', transform=RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True))\n",
        "        self.train_data, self.val_data, self.test_data = self.dataset[0]\n",
        "\n",
        "    def run_vgae(self):\n",
        "        vgae_model = VGAEModel(self.dataset, self.device)\n",
        "        for epoch in range(301):\n",
        "            loss = vgae_model.train(self.train_data)\n",
        "            val_auc, val_ap = vgae_model.test(self.test_data)\n",
        "            if epoch % 50 == 0:\n",
        "                print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')\n",
        "        test_auc, test_ap = vgae_model.test(self.test_data)\n",
        "        print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')\n",
        "        z = vgae_model.model.encode(self.test_data.x, self.test_data.edge_index)\n",
        "        Ahat = torch.sigmoid(z @ z.T)\n",
        "        print(Ahat)\n",
        "\n",
        "    def run_dgcnn(self):\n",
        "        train_pos_data_list = SealProcessing.process(self.train_data, self.train_data.pos_edge_label_index, 1)\n",
        "        train_neg_data_list = SealProcessing.process(self.train_data, self.train_data.neg_edge_label_index, 0)\n",
        "        val_pos_data_list = SealProcessing.process(self.val_data, self.val_data.pos_edge_label_index, 1)\n",
        "        val_neg_data_list = SealProcessing.process(self.val_data, self.val_data.neg_edge_label_index, 0)\n",
        "        test_pos_data_list = SealProcessing.process(self.test_data, self.test_data.pos_edge_label_index, 1)\n",
        "        test_neg_data_list = SealProcessing.process(self.test_data, self.test_data.neg_edge_label_index, 0)\n",
        "\n",
        "        train_dataset = train_pos_data_list + train_neg_data_list\n",
        "        val_dataset = val_pos_data_list + val_neg_data_list\n",
        "        test_dataset = test_pos_data_list + test_neg_data_list\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "        dgcnn_model = DGCNNModel(train_dataset[0].num_features).to(self.device)\n",
        "        optimizer = torch.optim.Adam(params=dgcnn_model.parameters(), lr=0.0001)\n",
        "        criterion = BCEWithLogitsLoss()\n",
        "\n",
        "        def train():\n",
        "            dgcnn_model.train()\n",
        "            total_loss = 0\n",
        "            for data in train_loader:\n",
        "                data = data.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                out = dgcnn_model(data.x, data.edge_index, data.batch)\n",
        "                loss = criterion(out.view(-1), data.y.to(torch.float))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += float(loss) * data.num_graphs\n",
        "            return total_loss / len(train_dataset)\n",
        "\n",
        "        @torch.no_grad()\n",
        "        def test(loader):\n",
        "            dgcnn_model.eval()\n",
        "            y_pred, y_true = [], []\n",
        "            for data in loader:\n",
        "                data = data.to(self.device)\n",
        "                out = dgcnn_model(data.x, data.edge_index, data.batch)\n",
        "                y_pred.append(out.view(-1).cpu())\n",
        "                y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
        "            auc = roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "            ap = average_precision_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "            return auc, ap\n",
        "\n",
        "        for epoch in range(31):\n",
        "            loss = train()\n",
        "            val_auc, val_ap = test(val_loader)\n",
        "            print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')\n",
        "\n",
        "        test_auc, test_ap = test(test_loader)\n",
        "        print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')"
      ],
      "metadata": {
        "id": "X63UW888x_ZE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Main Code**"
      ],
      "metadata": {
        "id": "okJcQ_T4ztoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_modeling = GraphModeling()"
      ],
      "metadata": {
        "id": "UdFkh74B_61j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_modeling.run_vgae()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx13bRwLELS7",
        "outputId": "b0034145-c1c1-410e-983e-afaf62ed84a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 | Loss: 3.5497 | Val AUC: 0.7349 | Val AP: 0.7365\n",
            "Epoch 50 | Loss: 0.9364 | Val AUC: 0.9047 | Val AP: 0.9070\n",
            "Epoch 100 | Loss: 0.8879 | Val AUC: 0.9097 | Val AP: 0.9162\n",
            "Epoch 150 | Loss: 0.8473 | Val AUC: 0.9044 | Val AP: 0.9151\n",
            "Epoch 200 | Loss: 0.8559 | Val AUC: 0.9092 | Val AP: 0.9233\n",
            "Epoch 250 | Loss: 0.8468 | Val AUC: 0.9118 | Val AP: 0.9251\n",
            "Epoch 300 | Loss: 0.8320 | Val AUC: 0.9179 | Val AP: 0.9298\n",
            "Test AUC: 0.9179 | Test AP 0.9298\n",
            "tensor([[0.7273, 0.5806, 0.8028,  ..., 0.4389, 0.8306, 0.8148],\n",
            "        [0.5806, 0.8058, 0.6865,  ..., 0.6603, 0.6286, 0.6312],\n",
            "        [0.8028, 0.6865, 0.9245,  ..., 0.4668, 0.8917, 0.8692],\n",
            "        ...,\n",
            "        [0.4389, 0.6603, 0.4668,  ..., 0.9159, 0.3805, 0.3702],\n",
            "        [0.8306, 0.6286, 0.8917,  ..., 0.3805, 0.9535, 0.9479],\n",
            "        [0.8148, 0.6312, 0.8692,  ..., 0.3702, 0.9479, 0.9468]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_modeling.run_dgcnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTxN3s3jmMSY",
        "outputId": "34ecce75-ae33-4565-e8af-fc43eb6e90cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 | Loss: 0.6990 | Val AUC: 0.8034 | Val AP: 0.8094\n",
            "Epoch  1 | Loss: 0.6193 | Val AUC: 0.8451 | Val AP: 0.8538\n",
            "Epoch  2 | Loss: 0.5885 | Val AUC: 0.8602 | Val AP: 0.8637\n",
            "Epoch  3 | Loss: 0.5800 | Val AUC: 0.8698 | Val AP: 0.8814\n",
            "Epoch  4 | Loss: 0.5762 | Val AUC: 0.8736 | Val AP: 0.8827\n",
            "Epoch  5 | Loss: 0.5735 | Val AUC: 0.8777 | Val AP: 0.8893\n",
            "Epoch  6 | Loss: 0.5714 | Val AUC: 0.8812 | Val AP: 0.8910\n",
            "Epoch  7 | Loss: 0.5697 | Val AUC: 0.8814 | Val AP: 0.8794\n",
            "Epoch  8 | Loss: 0.5684 | Val AUC: 0.8890 | Val AP: 0.8972\n",
            "Epoch  9 | Loss: 0.5671 | Val AUC: 0.8910 | Val AP: 0.8896\n",
            "Epoch 10 | Loss: 0.5655 | Val AUC: 0.8871 | Val AP: 0.8841\n",
            "Epoch 11 | Loss: 0.5642 | Val AUC: 0.8922 | Val AP: 0.8903\n",
            "Epoch 12 | Loss: 0.5623 | Val AUC: 0.8956 | Val AP: 0.8932\n",
            "Epoch 13 | Loss: 0.5592 | Val AUC: 0.8947 | Val AP: 0.8906\n",
            "Epoch 14 | Loss: 0.5568 | Val AUC: 0.8961 | Val AP: 0.8967\n",
            "Epoch 15 | Loss: 0.5551 | Val AUC: 0.8950 | Val AP: 0.8941\n",
            "Epoch 16 | Loss: 0.5539 | Val AUC: 0.8885 | Val AP: 0.8789\n",
            "Epoch 17 | Loss: 0.5527 | Val AUC: 0.8949 | Val AP: 0.8869\n",
            "Epoch 18 | Loss: 0.5520 | Val AUC: 0.8906 | Val AP: 0.8797\n",
            "Epoch 19 | Loss: 0.5519 | Val AUC: 0.8922 | Val AP: 0.8811\n",
            "Epoch 20 | Loss: 0.5507 | Val AUC: 0.8859 | Val AP: 0.8782\n",
            "Epoch 21 | Loss: 0.5503 | Val AUC: 0.8840 | Val AP: 0.8740\n",
            "Epoch 22 | Loss: 0.5497 | Val AUC: 0.8910 | Val AP: 0.8813\n",
            "Epoch 23 | Loss: 0.5497 | Val AUC: 0.8862 | Val AP: 0.8788\n",
            "Epoch 24 | Loss: 0.5488 | Val AUC: 0.8829 | Val AP: 0.8756\n",
            "Epoch 25 | Loss: 0.5475 | Val AUC: 0.8826 | Val AP: 0.8770\n",
            "Epoch 26 | Loss: 0.5467 | Val AUC: 0.8882 | Val AP: 0.8842\n",
            "Epoch 27 | Loss: 0.5473 | Val AUC: 0.8834 | Val AP: 0.8776\n",
            "Epoch 28 | Loss: 0.5465 | Val AUC: 0.8844 | Val AP: 0.8788\n",
            "Epoch 29 | Loss: 0.5471 | Val AUC: 0.8802 | Val AP: 0.8768\n",
            "Epoch 30 | Loss: 0.5479 | Val AUC: 0.8847 | Val AP: 0.8795\n",
            "Test AUC: 0.8899 | Test AP 0.8929\n"
          ]
        }
      ]
    }
  ]
}